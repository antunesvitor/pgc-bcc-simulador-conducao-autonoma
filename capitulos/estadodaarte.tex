\chapter{Estado da Arte}\label{cap:estArte}
Neste capítulo, serão discutidos e analisados trabalhos que envolvem a criação de agentes inteligentes em ambientes virtuais, a primeira seção será dedicada àqueles que não utilizam o pacote ML-Agents. Na outra seção, porém será visto projetos que se utilizam da biblioteca da Unity3D.

\section*{TORCS, CARLA e ALVINN}
Um dos primeiros e mais conhecidos projetos que envolve direção autônoma é o ALVINN (\citeonline{Pomerleau1991}), nele foi utilizado aprendizado por imitação, onde usaram de uma câmera posicionada no painel do veículo e um humano dirigindo, os dados gerados do especialista foram usados para treinar a rede neural. O veículo conseguiu percorrer uma distância de 400 metros a uma velocidade de 1,5 m/s. 

TORCS é um simulador de código aberto bastante modular que pode ser usado para a criação de agentes artificialmente inteligentes. Sua portabilidade e modularidade é ideal para poder modificar o ambiente de modo a aumentar os desafios dos agentes que serão treinados nele, porém seu escopo se limita a pistas de corridas, então não é o ideal para percorrer trajetos urbanos que contenha pedestres, semáforos, regras de trânsito, etc (\citeonline{TORCS}).

Um projeto muito similar ao que este trabalho se propõe a fazer é o \textbf{CARLA}. Car Learning to Act (CARLA) é um ambiente de código aberto de treinamento condução autônoma de veículos terrestres, foi desenvolvido usando a \textbf{Unreal Engine 4}. A simulação inclui clima dinâmico, uso de visão computacional, obstáculos dinâmicos como carros e pedestres além de visual fotorrealista. Quanto ao treinamento utiliza-se de três métodos: um fluxo modular, aprendizado por imitação e aprendizado por reforço, treinaram os agentes em cada método em 4 níveis diferentes de dificuldade, e então postos a testes em climas e uma cidade distinta. O resultado foi surpreendente, com o aprendizado por reforço tendo um desempenho muito inferior aos outros dois métodos (\citeonline{pmlr-v78-dosovitskiy17a}).

\section*{Criação de agentes inteligentes utilizando ML-Agents}\label{sec:primTrab}
O projeto desenvolvido por (\citeonline{s21020492}) também envolve um carro autônomo, apesar de não envolver um ambiente urbano e sim uma pista em formato de 8 (para treino) e outra com começo e fim (para teste). O trabalho analisa os dados da dirigibilidade comparando um humano em um simulador, um agente criado usando aprendizado por imitação e outro agente utilizando \textbf{RL}. 

Outro trabalho foi feito por (\citeonline{mexas2021}), que também se trata de um veículo autônomo, mas desta vez é um veleiro. Neste projeto, o autor faz um estudo comparativo dos algoritmos \textbf{PPO} e \textbf{SAC} para aprendizado por reforço, e os algoritmos \textbf{BC} e \textbf{GAIL} para \textbf{IL}. O ambiente dele considera a ação do vento sobre o veleiro e ao analisar os dados conclui que o primeiro algoritmo de \textbf{RL} é o que apresentou o melhor desempenho.

\section*{Utilização de Aprendizado por Reforço e Imitação em jogos}
Outro projeto desenvolveu e analisou modelos de para controle de jogos eletrônicos utilizando-se de RL e IL (\citeonline{Souza2023}). O jogo utilizado para a análise foi o \textit{Sonic: The Hedgehog}, gerando modelos com GAIL e BC com PPO para otimização de política, os mesmos algoritmos que será utilizado neste projeto. O jogo possui diversos níveis nos quais os modelos foram treinados, que variam em extensão e complexidade, alguns deles requerem que pequenos \textit{puzzles} sejam solucionados para serem concluídos. No fim dos testes, os modelos que se utilizaram de IL obtiveram um desempenho melhor, além de um treino com convergência mais rápida.
%Escrever aqui os resultados que ele obteve